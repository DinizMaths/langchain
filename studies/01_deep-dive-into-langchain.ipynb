{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blockchain is a digital ledger that stores information in blocks that are linked together in a chain. Each block contains a list of transactions, and once a block is added to the chain, it cannot be altered or deleted. This makes blockchain secure and transparent, as all transactions are recorded and verified by a network of computers. It is commonly used for cryptocurrencies like Bitcoin, but can also be used for other types of transactions and data storage.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    api_key=OPENAI_API_KEY\n",
    ")\n",
    "\n",
    "output = llm.invoke(\"Explain the concept of blockchain in simple terms\")\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blockchain is a digital ledger that stores information in blocks that are linked together in a chain. Each block contains a list of transactions, and once a block is added to the chain, it cannot be altered or deleted. This makes blockchain secure and transparent, as all transactions are recorded and verified by a network of computers. It is commonly used for cryptocurrencies like Bitcoin, but can also be used for other types of transactions and data storage.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0,\n",
    "    api_key=OPENAI_API_KEY\n",
    ")\n",
    "\n",
    "output = llm.invoke(\"Explain the concept of blockchain in simple terms\")\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Um blockchain é um registro digital de transações que é armazenado em vários computadores em uma rede descentralizada.\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import (\n",
    "    SystemMessage,\n",
    "    AIMessage,\n",
    "    HumanMessage\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a blockchain expert that respons every question with a simple answer in portuguese.\"),\n",
    "    HumanMessage(content=\"What is blockchain?\")\n",
    "]\n",
    "\n",
    "output = llm.invoke(messages)\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_llm_cache\n",
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(\n",
    "    model_name=\"gpt-3.5-turbo-instruct\",\n",
    "    api_key=OPENAI_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In Memory Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Why couldn't the pirate play cards?\n",
      "\n",
      "Because he was sitting on the deck!\n",
      "CPU times: user 7.1 ms, sys: 0 ns, total: 7.1 ms\n",
      "Wall time: 901 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from langchain.cache import InMemoryCache\n",
    "\n",
    "set_llm_cache(InMemoryCache())\n",
    "\n",
    "prompt = \"Tell me a pirate joke\"\n",
    "\n",
    "output = llm.invoke(prompt)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Why couldn't the pirate play cards?\n",
      "\n",
      "Because he was sitting on the deck!\n",
      "CPU times: user 456 μs, sys: 0 ns, total: 456 μs\n",
      "Wall time: 451 μs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "prompt = \"Tell me a pirate joke\"\n",
    "\n",
    "output = llm.invoke(prompt)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQLite Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Why did the pirate go to therapy?\n",
      "\n",
      "Because he was feeling arrrrrrrr-nxious!\n",
      "CPU times: user 36.9 ms, sys: 0 ns, total: 36.9 ms\n",
      "Wall time: 1.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from langchain.cache import SQLiteCache\n",
    "\n",
    "set_llm_cache(SQLiteCache())\n",
    "\n",
    "prompt = \"Tell me a pirate joke\"\n",
    "\n",
    "output = llm.invoke(prompt)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Why did the pirate go to therapy?\n",
      "\n",
      "Because he was feeling arrrrrrrr-nxious!\n",
      "CPU times: user 5.33 ms, sys: 0 ns, total: 5.33 ms\n",
      "Wall time: 4.46 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "prompt = \"Tell me a pirate joke\"\n",
    "\n",
    "output = llm.invoke(prompt)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verse 1:\n",
      "In a field of flowers, I found a rock\n",
      "Among the petals, it stood out in shock\n",
      "A symbol of strength, solid and true\n",
      "Just like my love, forever for you\n",
      "\n",
      "Chorus:\n",
      "Flowers and rocks, a perfect pair\n",
      "Beauty and strength, beyond compare\n",
      "In your arms, I feel complete\n",
      "Our love, like flowers and rocks, so sweet\n",
      "\n",
      "Verse 2:\n",
      "The flowers bloom, the rocks remain\n",
      "Through storms and sunshine, they both sustain\n",
      "Just like our love, through highs and lows\n",
      "Together we'll weather all the blows\n",
      "\n",
      "Chorus:\n",
      "Flowers and rocks, a perfect pair\n",
      "Beauty and strength, beyond compare\n",
      "In your arms, I feel complete\n",
      "Our love, like flowers and rocks, so sweet\n",
      "\n",
      "Bridge:\n",
      "With petals soft and colors bright\n",
      "And rocks so solid, a steadfast might\n",
      "Together they create a perfect blend\n",
      "Just like us, my love, until the end\n",
      "\n",
      "Chorus:\n",
      "Flowers and rocks, a perfect pair\n",
      "Beauty and strength, beyond compare\n",
      "In your arms, I feel complete\n",
      "Our love, like flowers and rocks, so sweet\n",
      "\n",
      "Outro:\n",
      "So let's bloom like flowers and stand like rocks\n",
      "Facing the world with love that never stops\n",
      "Together we'll weather all life brings\n",
      "Our love, like flowers and rocks, forever sings.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Write a love song about flowers and rocks.\"\n",
    "\n",
    "output = llm.invoke(prompt)\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verse 1:\n",
      "In a field of flowers, I found you\n",
      "Among the rocks, you stood so true\n",
      "Your beauty blooms like a rose in June\n",
      "A love so strong, it will never swoon\n",
      "\n",
      "Chorus:\n",
      "You're my flower in a world of rocks\n",
      "You're my anchor in the stormy docks\n",
      "Together we'll weather any storm\n",
      "Our love will always keep us warm\n",
      "\n",
      "Verse 2:\n",
      "Among the rocks, our love will grow\n",
      "Like a wildflower, it will show\n",
      "Through the toughest times, we will stand\n",
      "Hand in hand, we'll conquer all we can\n",
      "\n",
      "Chorus:\n",
      "You're my flower in a world of rocks\n",
      "You're my anchor in the stormy docks\n",
      "Together we'll weather any storm\n",
      "Our love will always keep us warm\n",
      "\n",
      "Bridge:\n",
      "Like a rock that never crumbles\n",
      "Our love will never stumble\n",
      "Through the trials and the pain\n",
      "Our love will always remain\n",
      "\n",
      "Chorus:\n",
      "You're my flower in a world of rocks\n",
      "You're my anchor in the stormy docks\n",
      "Together we'll weather any storm\n",
      "Our love will always keep us warm\n",
      "\n",
      "Outro:\n",
      "In a field of flowers, I found you\n",
      "Among the rocks, our love is true\n",
      "Forever blooming, forever strong\n",
      "Our love will last a lifetime long."
     ]
    }
   ],
   "source": [
    "prompt = \"Write a love song about flowers and rocks.\"\n",
    "\n",
    "for chunk in llm.stream(prompt):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = '''You are a code expert that responds every question with a simple answer in portuguese.\n",
    "Write a few lines of code that prints \"Hello, World!\" in {language} using comments in {comment_language}.'''\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are a code expert that responds every question with a simple answer in portuguese.\\nWrite a few lines of code that prints \"Hello, World!\" in Python using comments in Japanese.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = prompt_template.format(language=\"Python\", comment_language=\"Japanese\")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are a code expert that responds every question with a simple answer in portuguese.\\nWrite a few lines of code that prints \"Hello, World!\" in Python using comments in Japanese.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# こんにちは、世界！\n",
      "print(\"Hello, World!\")\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "output = llm.invoke(prompt)\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-udemy-langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
