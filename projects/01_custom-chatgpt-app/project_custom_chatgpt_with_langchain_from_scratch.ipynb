{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60530a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv \n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19e164b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0b6c5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=1)\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    input_variables=[\"content\"],\n",
    "    messages=[\n",
    "        SystemMessage(content='You respond only in Portuguese.'),\n",
    "        HumanMessagePromptTemplate.from_template(\"{content}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5941417a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You respond only in Portuguese.\n",
      "Human: Olá, como vai?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'content': 'Olá, como vai?', 'text': 'Olá! Estou bem, obrigado. E você, como está? Posso te ajudar com alguma coisa?'}\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You respond only in Portuguese.\n",
      "Human: Gostaria de saber mais sobre Blockchain\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'content': 'Gostaria de saber mais sobre Blockchain', 'text': 'Claro! O blockchain é uma tecnologia de registro distribuído que permite armazenar e compartilhar informações de forma segura e transparente. Ele é frequentemente associado às criptomoedas, como o Bitcoin, pois é a tecnologia por trás da sua operação. No entanto, o blockchain tem aplicações em diversos outros setores, como logística, saúde, votação eletrônica, entre outros. Ele funciona através de blocos de informações encadeados de forma criptografada, garantindo a integridade e a imutabilidade dos dados. O sistema é descentralizado e não depende de uma autoridade central para validar as transações, o que o torna mais seguro e confiável. Espero que isso esclareça um pouco mais sobre o blockchain! Se tiver mais alguma dúvida, estou à disposição.'}\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You respond only in Portuguese.\n",
      "Human: it\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'content': 'it', 'text': 'Olá! Como posso ajudá-lo hoje?'}\n",
      "====================================================================================================\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    content = input('Your prompt: ')\n",
    "\n",
    "    if content.lower() in ['quit', 'exit', 'bye']:\n",
    "        print('Goodbye!')\n",
    "        break\n",
    "    \n",
    "    response = chain.invoke({'content': content})\n",
    "\n",
    "    print(response)\n",
    "    print('=' * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1370c0b7",
   "metadata": {},
   "source": [
    "## Adding Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0a3e2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0)\n",
    "\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key='chat_history',\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    input_variables=[\"content\", \"chat_history\"],\n",
    "    messages=[\n",
    "        SystemMessage(content=\"You are a chatbot having a conversation with a human.\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{content}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    memory=memory,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4da64204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'Olá, qual seu nome?', 'chat_history': [HumanMessage(content='Olá, qual seu nome?'), AIMessage(content='Olá! Eu sou um assistente virtual, não tenho um nome específico. Como posso ajudar você hoje?')], 'text': 'Olá! Eu sou um assistente virtual, não tenho um nome específico. Como posso ajudar você hoje?'}\n",
      "====================================================================================================\n",
      "{'content': 'Im 50 years old', 'chat_history': [HumanMessage(content='Olá, qual seu nome?'), AIMessage(content='Olá! Eu sou um assistente virtual, não tenho um nome específico. Como posso ajudar você hoje?'), HumanMessage(content='Im 50 years old'), AIMessage(content=\"That's great! How are you feeling about being 50?\")], 'text': \"That's great! How are you feeling about being 50?\"}\n",
      "====================================================================================================\n",
      "{'content': 'How old am I?', 'chat_history': [HumanMessage(content='Olá, qual seu nome?'), AIMessage(content='Olá! Eu sou um assistente virtual, não tenho um nome específico. Como posso ajudar você hoje?'), HumanMessage(content='Im 50 years old'), AIMessage(content=\"That's great! How are you feeling about being 50?\"), HumanMessage(content='How old am I?'), AIMessage(content=\"I'm sorry, but I don't have access to your personal information such as your age. If you'd like to share that information with me, feel free to do so!\")], 'text': \"I'm sorry, but I don't have access to your personal information such as your age. If you'd like to share that information with me, feel free to do so!\"}\n",
      "====================================================================================================\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    content = input('Your prompt: ')\n",
    "\n",
    "    if content.lower() in ['quit', 'exit', 'bye']:\n",
    "        print('Goodbye!')\n",
    "        break\n",
    "    \n",
    "    response = chain.invoke({'content': content})\n",
    "\n",
    "    print(response)\n",
    "    print('=' * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28677aa0",
   "metadata": {},
   "source": [
    "## Saving Chat Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "723b59ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import FileChatMessageHistory\n",
    "\n",
    "llm = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=1)\n",
    "\n",
    "history = FileChatMessageHistory('chat_history.json')\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key='chat_history',\n",
    "    chat_memory=history,\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    input_variables=[\"content\", \"chat_history\"],\n",
    "    messages=[\n",
    "        SystemMessage(content=\"You are a chatbot having a conversation with a human.\"),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"), \n",
    "        HumanMessagePromptTemplate.from_template(\"{content}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    memory=memory,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4486ed34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'Olá, como está?', 'chat_history': [], 'text': 'Olá! Estou aqui e pronto para conversar. Como posso ajudá-lo hoje?'}\n",
      "====================================================================================================\n",
      "{'content': 'Me ajude a iniciar um código FastAPI em python?', 'chat_history': [HumanMessage(content='Olá, como está?'), AIMessage(content='Olá! Estou aqui e pronto para conversar. Como posso ajudá-lo hoje?')], 'text': 'Claro! Vou te mostrar um exemplo simples de código FastAPI em Python para te ajudar a começar. Aqui está um exemplo de um arquivo chamado `main.py`:\\n\\n```python\\nfrom fastapi import FastAPI\\n\\n# Criar uma instância do FastAPI\\napp = FastAPI()\\n\\n# Rota padrão\\n@app.get(\"/\")\\nasync def read_root():\\n    return {\"Hello\": \"World\"}\\n\\n# Rota com parâmetro\\n@app.get(\"/items/{item_id}\")\\nasync def read_item(item_id: int, q: str = None):\\n    return {\"item_id\": item_id, \"q\": q}\\n\\n# Executar o servidor\\nif __name__ == \"__main__\":\\n    import uvicorn\\n    uvicorn.run(app, host=\"127.0.0.1\", port=8000)\\n```\\n\\nPara executar o código, você precisará instalar o FastAPI e o Uvicorn. Você pode fazer isso executando os seguintes comandos no seu terminal:\\n\\n```\\npip install fastapi\\npip install uvicorn\\n```\\n\\nEm seguida, para iniciar o servidor, você pode executar o seguinte comando no terminal:\\n\\n```\\nuvicorn main:app --reload\\n```\\n\\nIsso iniciará o servidor FastAPI e você poderá acessar as rotas definidas no navegador ou através de uma ferramenta como o Postman. Espero que isso te ajude a começar! Se tiver mais dúvidas, é só perguntar.'}\n",
      "====================================================================================================\n",
      "{'content': 'Como enviar dados?', 'chat_history': [HumanMessage(content='Olá, como está?'), AIMessage(content='Olá! Estou aqui e pronto para conversar. Como posso ajudá-lo hoje?'), HumanMessage(content='Me ajude a iniciar um código FastAPI em python?'), AIMessage(content='Claro! Vou te mostrar um exemplo simples de código FastAPI em Python para te ajudar a começar. Aqui está um exemplo de um arquivo chamado `main.py`:\\n\\n```python\\nfrom fastapi import FastAPI\\n\\n# Criar uma instância do FastAPI\\napp = FastAPI()\\n\\n# Rota padrão\\n@app.get(\"/\")\\nasync def read_root():\\n    return {\"Hello\": \"World\"}\\n\\n# Rota com parâmetro\\n@app.get(\"/items/{item_id}\")\\nasync def read_item(item_id: int, q: str = None):\\n    return {\"item_id\": item_id, \"q\": q}\\n\\n# Executar o servidor\\nif __name__ == \"__main__\":\\n    import uvicorn\\n    uvicorn.run(app, host=\"127.0.0.1\", port=8000)\\n```\\n\\nPara executar o código, você precisará instalar o FastAPI e o Uvicorn. Você pode fazer isso executando os seguintes comandos no seu terminal:\\n\\n```\\npip install fastapi\\npip install uvicorn\\n```\\n\\nEm seguida, para iniciar o servidor, você pode executar o seguinte comando no terminal:\\n\\n```\\nuvicorn main:app --reload\\n```\\n\\nIsso iniciará o servidor FastAPI e você poderá acessar as rotas definidas no navegador ou através de uma ferramenta como o Postman. Espero que isso te ajude a começar! Se tiver mais dúvidas, é só perguntar.')], 'text': 'Para enviar dados para o servidor FastAPI, você pode fazer uma solicitação HTTP usando ferramentas como o Postman, cURL ou bibliotecas em Python como o requests.\\n\\nAqui está um exemplo simples de como você pode enviar dados para o servidor FastAPI usando o Postman:\\n\\n1. Abra o Postman e crie uma nova solicitação.\\n2. Defina a URL da solicitação como o endpoint apropriado do seu servidor FastAPI (por exemplo, `http://127.0.0.1:8000/items`).\\n3. Se estiver enviando dados para uma rota que espera parâmetros, você pode adicionar os parâmetros na aba \"Params\" do Postman.\\n4. Se estiver enviando dados no corpo da solicitação, você pode selecionar o tipo de corpo da solicitação (por exemplo, JSON) na aba \"Body\" e adicionar os dados no formato apropriado.\\n\\nSe estiver enviando dados para uma rota que espera parâmetros via método POST, você pode fazer algo semelhante ao exemplo abaixo usando a biblioteca requests em Python:\\n\\n```python\\nimport requests\\n\\nurl = \\'http://127.0.0.1:8000/items\\'\\ndata = {\\'item_id\\': 1, \\'q\\': \\'sample\\'}\\n\\nresponse = requests.post(url, json=data)\\n\\nprint(response.json())\\n```\\n\\nEste é apenas um exemplo simples de como enviar dados para o seu servidor FastAPI. Você pode personalizar de acordo com as suas necessidades e requisitos específicos. Espero que isso ajude! Se tiver mais dúvidas, fique à vontade para perguntar.'}\n",
      "====================================================================================================\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    content = input('Your prompt: ')\n",
    "    if content.lower() in ['quit', 'exit', 'bye']:\n",
    "        print('Goodbye!')\n",
    "        break\n",
    "    \n",
    "    response = chain.invoke({'content': content})\n",
    "\n",
    "    print(response)\n",
    "    print('=' * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42074641",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='Olá, como está?'), AIMessage(content='Olá! Estou aqui e pronto para conversar. Como posso ajudá-lo hoje?'), HumanMessage(content='Me ajude a iniciar um código FastAPI em python?'), AIMessage(content='Claro! Vou te mostrar um exemplo simples de código FastAPI em Python para te ajudar a começar. Aqui está um exemplo de um arquivo chamado `main.py`:\\n\\n```python\\nfrom fastapi import FastAPI\\n\\n# Criar uma instância do FastAPI\\napp = FastAPI()\\n\\n# Rota padrão\\n@app.get(\"/\")\\nasync def read_root():\\n    return {\"Hello\": \"World\"}\\n\\n# Rota com parâmetro\\n@app.get(\"/items/{item_id}\")\\nasync def read_item(item_id: int, q: str = None):\\n    return {\"item_id\": item_id, \"q\": q}\\n\\n# Executar o servidor\\nif __name__ == \"__main__\":\\n    import uvicorn\\n    uvicorn.run(app, host=\"127.0.0.1\", port=8000)\\n```\\n\\nPara executar o código, você precisará instalar o FastAPI e o Uvicorn. Você pode fazer isso executando os seguintes comandos no seu terminal:\\n\\n```\\npip install fastapi\\npip install uvicorn\\n```\\n\\nEm seguida, para iniciar o servidor, você pode executar o seguinte comando no terminal:\\n\\n```\\nuvicorn main:app --reload\\n```\\n\\nIsso iniciará o servidor FastAPI e você poderá acessar as rotas definidas no navegador ou através de uma ferramenta como o Postman. Espero que isso te ajude a começar! Se tiver mais dúvidas, é só perguntar.'), HumanMessage(content='Como enviar dados?'), AIMessage(content='Para enviar dados para o servidor FastAPI, você pode fazer uma solicitação HTTP usando ferramentas como o Postman, cURL ou bibliotecas em Python como o requests.\\n\\nAqui está um exemplo simples de como você pode enviar dados para o servidor FastAPI usando o Postman:\\n\\n1. Abra o Postman e crie uma nova solicitação.\\n2. Defina a URL da solicitação como o endpoint apropriado do seu servidor FastAPI (por exemplo, `http://127.0.0.1:8000/items`).\\n3. Se estiver enviando dados para uma rota que espera parâmetros, você pode adicionar os parâmetros na aba \"Params\" do Postman.\\n4. Se estiver enviando dados no corpo da solicitação, você pode selecionar o tipo de corpo da solicitação (por exemplo, JSON) na aba \"Body\" e adicionar os dados no formato apropriado.\\n\\nSe estiver enviando dados para uma rota que espera parâmetros via método POST, você pode fazer algo semelhante ao exemplo abaixo usando a biblioteca requests em Python:\\n\\n```python\\nimport requests\\n\\nurl = \\'http://127.0.0.1:8000/items\\'\\ndata = {\\'item_id\\': 1, \\'q\\': \\'sample\\'}\\n\\nresponse = requests.post(url, json=data)\\n\\nprint(response.json())\\n```\\n\\nEste é apenas um exemplo simples de como enviar dados para o seu servidor FastAPI. Você pode personalizar de acordo com as suas necessidades e requisitos específicos. Espero que isso ajude! Se tiver mais dúvidas, fique à vontade para perguntar.')]\n"
     ]
    }
   ],
   "source": [
    "print(history.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32cfdd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "514dcc35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>human</td>\n",
       "      <td>{'content': 'Olá, como está?', 'additional_kwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ai</td>\n",
       "      <td>{'content': 'Olá! Estou aqui e pronto para con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>human</td>\n",
       "      <td>{'content': 'Me ajude a iniciar um código Fast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ai</td>\n",
       "      <td>{'content': 'Claro! Vou te mostrar um exemplo ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>human</td>\n",
       "      <td>{'content': 'Como enviar dados?', 'additional_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ai</td>\n",
       "      <td>{'content': 'Para enviar dados para o servidor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    type                                               data\n",
       "0  human  {'content': 'Olá, como está?', 'additional_kwa...\n",
       "1     ai  {'content': 'Olá! Estou aqui e pronto para con...\n",
       "2  human  {'content': 'Me ajude a iniciar um código Fast...\n",
       "3     ai  {'content': 'Claro! Vou te mostrar um exemplo ...\n",
       "4  human  {'content': 'Como enviar dados?', 'additional_...\n",
       "5     ai  {'content': 'Para enviar dados para o servidor..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_json('chat_history.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
